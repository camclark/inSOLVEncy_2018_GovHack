{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg') \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os \n",
    "USER_DIR = os.path.expanduser('~')\n",
    "DATA_DIR = os.path.join(USER_DIR, 'dev','comp','govhack18','data')\n",
    "print(os.listdir(DATA_DIR))\n",
    "\n",
    "TMP_DIR = os.path.join(USER_DIR, 'tmp','gh')\n",
    "BEST_MODEL_PATH = os.path.join(TMP_DIR, 'model.h5')\n",
    "COLUMN_JSON = os.path.join(TMP_DIR, 'columns.json')\n",
    "\n",
    "TRAIN_VAL_SPLIT = 0.8\n",
    "RANDOM_STATE = 4814\n",
    "\n",
    "INPUT_CSV = 'train_8_1500.csv'\n",
    "fpath = os.path.join(DATA_DIR, INPUT_CSV)\n",
    "print('fpath = ', fpath) \n",
    "\n",
    "df = pd.read_csv(fpath)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "IGNORE_COLS = ['Unique ID', 'Calendar Year of Insolvency']\n",
    "df = df.drop(labels = IGNORE_COLS, axis = 1)\n",
    "print('df.columns = ', df.columns)\n",
    "\n",
    "# print(df['Sex of Debtor'].unique())\n",
    "# df = df.replace(['Not Stated'], ['Unknown'])\n",
    "print(df['Debtor Income'].unique())\n",
    "\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "print(df.nunique())\n",
    "\n",
    "df = df.astype('category')\n",
    "print(df.head())\n",
    "\n",
    "df = pd.get_dummies(df)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "df = df.drop(labels = ['Y_0'], axis = 1)\n",
    "    \n",
    "dfY1 = df[df['Y_1'] == 1]\n",
    "print('len(dfY1) = ', len(dfY1.index))\n",
    "\n",
    "dfY0 = df[df['Y_1'] == 0]\n",
    "print('len(dfY0) = ', len(dfY0.index))\n",
    "# print(dfY0.head())\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "train_df1, val_df1 = train_test_split(dfY1, train_size=TRAIN_VAL_SPLIT,\n",
    "                                        random_state=RANDOM_STATE)\n",
    "train_df, val_df = train_test_split(dfY0, train_size=TRAIN_VAL_SPLIT,\n",
    "                                        random_state=RANDOM_STATE)\n",
    "\n",
    "train_df = (train_df.append(train_df1)).sample(frac=1)\n",
    "val_df = (val_df.append(val_df1)).sample(frac=1)\n",
    "print('len(train_df) = ', len(train_df.index))\n",
    "print('len(val_df) = ', len(val_df.index))\n",
    "\n",
    "\n",
    "X_train = train_df.drop(labels = ['Y_1'], axis = 1)\n",
    "print('X_train.columns.columns = ', X_train.columns)\n",
    "X_train = X_train.values\n",
    "np.save(os.path.join(TMP_DIR, 'X_train.npy'), np.asarray(X_train))\n",
    "\n",
    "Y_train = (train_df['Y_1'].values)[..., np.newaxis]\n",
    "print('X,Y shapes = ', X_train.shape, Y_train.shape)\n",
    "np.save(os.path.join(TMP_DIR, 'Y_train.npy'), np.asarray(Y_train))\n",
    "\n",
    "X_val = val_df.drop(labels = ['Y_1'], axis = 1).values\n",
    "Y_val = (val_df['Y_1'].values)[..., np.newaxis]\n",
    "print('X,Y shapes = ', X_val.shape, Y_val.shape)\n",
    "np.save(os.path.join(TMP_DIR, 'X_val.npy'), np.asarray(X_val))\n",
    "np.save(os.path.join(TMP_DIR, 'Y_val.npy'), np.asarray(Y_val))\n",
    "\n",
    "\n",
    "# corr = df.corr()\n",
    "# # Generate a mask for the upper triangle\n",
    "# mask = np.zeros_like(corr, dtype=np.bool)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "# \n",
    "# # Set up the matplotlib figure\n",
    "# f, ax = plt.subplots(figsize=(11, 9))\n",
    "# \n",
    "# # Generate a custom diverging colormap\n",
    "# cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "# sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "# def make_model(input_shape):\n",
    "#     from keras.models import Model\n",
    "#     from keras.layers import Dense, BatchNormalization, Input, Dropout\n",
    "#\n",
    "#     in1 = Input(shape=[input_shape])\n",
    "#     x = in1\n",
    "#     # x = Dense(64, activation='relu')(x)\n",
    "#     # x = Dropout(0.5)(x)\n",
    "#     # x = BatchNormalization()(x)\n",
    "#\n",
    "#     # x = Dense(32, activation='relu')(x)\n",
    "#     # # x = Dropout(0.5)(x)\n",
    "#     # x = BatchNormalization()(x)\n",
    "#\n",
    "#     # x = Dense(32, activation='relu')(x)\n",
    "#     # # x = Dropout(0.5)(x)\n",
    "#     # x = BatchNormalization()(x)\n",
    "#\n",
    "#     x = Dense(1, activation='sigmoid')(x)\n",
    "#     model = Model(in1, x)\n",
    "#     print(model.summary())\n",
    "#     return model\n",
    "#\n",
    "#\n",
    "# # def top1acc(y_true, y_pred):\n",
    "# #     return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=1)\n",
    "# # _POS_WEIGHT = None\n",
    "# # def dk2_weighted_binary_crossentropy(y_true, y_pred):\n",
    "# #     return K.mean(tf_weighted_binary_crossentropy(y_true, y_pred, pos_weight=_POS_WEIGHT), axis=-1)\n",
    "#\n",
    "# # model_loss = 'binary_crossentropy'\n",
    "# model_compare_metric = 'val_loss'\n",
    "# model = make_model(X_train.shape[-1])\n",
    "#\n",
    "# # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['mae'])\n",
    "# model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "#\n",
    "#\n",
    "# from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras.callbacks import TensorBoard\n",
    "# ''' --> Callbacks '''\n",
    "# early_stop = EarlyStopping(monitor=model_compare_metric,\n",
    "#                            min_delta=0,\n",
    "#                            patience=32, verbose=1)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor=model_compare_metric,\n",
    "#                               factor=0.5, min_delta=0, verbose=1,\n",
    "#                               patience=10, cooldown=0)\n",
    "# tf_board = TensorBoard(log_dir=TMP_DIR, write_images=False)\n",
    "# save_best = ModelCheckpoint(monitor=model_compare_metric,\n",
    "#                                  save_weights_only=True,\n",
    "#                                  filepath=BEST_MODEL_PATH, save_best_only=True)\n",
    "#\n",
    "# callback_list = [early_stop, save_best, tf_board, reduce_lr]\n",
    "#\n",
    "# model.fit(X_train, Y_train, epochs=1000, batch_size=64, validation_data=(X_val, Y_val),\n",
    "#           callbacks=callback_list)\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "# def make_model():\n",
    "#     import xgboost as xgb\n",
    "#         print(\"Parameter optimization\")\n",
    "#     xgb_model = xgb.XGBClassifier()  # xgb_model = xgb.XGBRegressor()\n",
    "#     print('X.shape = ', X.shape)\n",
    "#     print('y.shape = ', y.shape)\n",
    "#     clf = GridSearchCV(xgb_model,\n",
    "#                        {'max_depth': [3, 4, 5],\n",
    "#                         'n_estimators': [30, 40, 50]\n",
    "#                         # , 'reg_alpha': [0.003, 0.001, 0.0003]\n",
    "#                         },\n",
    "#                     n_jobs=12, verbose=1)\n",
    "#     clf.fit(X, y)\n",
    "#     print(clf.best_score_)\n",
    "#     print(clf.best_params_)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
